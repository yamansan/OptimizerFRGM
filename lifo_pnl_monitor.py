#!/usr/bin/env python
"""
LIFO PnL Monitor
----------------
Continuously watches a fills CSV (generated by `continuous_fill_monitor.py`),
maintains a LIFO buy stack (price, quantity), and whenever a SELL order is
encountered it calculates realised PnL (and complement PnL if partial on the
first popped buy) using the same formula shown in `LIFO.ipynb`.

A record of each SELL event is appended to an output CSV.

USAGE EXAMPLE
-------------
python lifo_pnl_monitor.py \
       --csv-file data/output/ladder/continuous_fills.csv \
       --output lifo_pnl_results.csv
"""

import argparse
import csv
import os
import pickle
import sys
import time
from datetime import datetime
from typing import List, Tuple, Optional

import pandas as pd
import json

from config import CONTINUOUS_FILLS_CSV, LIFO_STREAMING_CSV

def load_config(config_file='config.json'):
    """Load configuration from a JSON file."""
    with open(config_file, 'r') as f:
        config = json.load(f)
    return config


# Load configuration
config = load_config()


PositionStack = List[Tuple[float, float]]  # (quantity, price) - qty>0 for long, qty<0 for short

# ---------------------------------------------------------------------------
# LIFO PnL calculation (using new logic that handles both long and short)
# ---------------------------------------------------------------------------

def calculate_lifo_pnl_and_update_stack(stack: List[Tuple[float, float]], qty: float, price: float) -> float:
    """
    Process a trade using LIFO logic and return realized PnL.
    stack: list of (quantity, price); qty>0 = long, qty<0 = short
    qty: trade quantity (positive for buy, negative for sell)
    price: trade price
    Returns: realized PnL for this trade
    """
    remaining = qty # This is signed quantity. If qty is positive, it is a buy. If qty is negative, it is a sell.
    pnl_this_trade = 0.0

    # 1Ô∏è‚É£ offset against opposite lots
    while remaining and stack and ((remaining > 0) ^ (stack[-1][0] > 0)): # This checks if the last lot has the opposite sign of the remaining quantity.
        lot_qty, lot_price = stack.pop()   # This is the last available lot in the stack.
        match = min(abs(remaining), abs(lot_qty))  # This is the quantity to match. 
                                                   # Match is already non-negative.

        if remaining < 0:        # selling long
            pnl_this_trade += (price - lot_price) * match * 16 * 62.5
        else:                    # buying to cover short
            pnl_this_trade += (lot_price - price) * match * 16 * 62.5

        # shrink lot & remaining
        if abs(lot_qty) > match: # This is the case where the last lot quantity is greater than the match quantity.
            stack.append((lot_qty / abs(lot_qty) * (abs(lot_qty) - match), lot_price)) # This adds the remaining quantity to the stack.
        remaining = remaining / abs(remaining) * (abs(remaining) - match) if remaining != 0 else 0 # This updates the remaining quantity.

    # 2Ô∏è‚É£ leftover becomes a new open lot
    if remaining: # This is the case where the remaining quantity is not zero.
        stack.append((remaining, price)) # This adds the remaining quantity to the stack.

    return pnl_this_trade


# ---------------------------------------------------------------------------
# Helper utilities
# ---------------------------------------------------------------------------

_DT_FORMAT_WITH_MS = "%Y-%m-%d %H:%M:%S.%f"
_DT_FORMAT_NO_MS = "%Y-%m-%d %H:%M:%S"


def parse_fill_datetime(date_str: str, time_str: str) -> datetime:
    """Return datetime constructed from *Date* and *Time* columns."""
    txt = f"{date_str} {time_str}"
    try:
        return datetime.strptime(txt, _DT_FORMAT_WITH_MS)
    except ValueError:
        return datetime.strptime(txt, _DT_FORMAT_NO_MS)

# ---------------------------------------------------------------------------
# Stack persistence functions
# ---------------------------------------------------------------------------

def save_stack_state(stack: PositionStack, last_row: int, processed_txns: set, state_file: str) -> None:
    """Save stack state to disk for persistence across restarts."""
    state = {
        'stack': stack,
        'last_processed_row': last_row,
        'processed_transactions': processed_txns
    }
    with open(state_file, 'wb') as f:
        pickle.dump(state, f)

def load_stack_state(state_file: str) -> Tuple[PositionStack, int, set]:
    """Load stack state from disk. Returns empty state if file doesn't exist."""
    if not os.path.exists(state_file):
        return [], 0, set()
    
    try:
        with open(state_file, 'rb') as f:
            state = pickle.load(f)
        return state['stack'], state['last_processed_row'], state['processed_transactions']
    except Exception as e:
        print(f"Warning: Could not load stack state ({e}). Starting fresh.")
        return [], 0, set()

# ---------------------------------------------------------------------------
# Run-once processing for event-driven mode
# ---------------------------------------------------------------------------

def process_lifo_once(csv_file: str, output_path: str, reset: bool = False) -> bool:
    """Process LIFO once and exit - for event-driven mode."""
    try:
        state_file = output_path.replace('.csv', '_state.pkl')
        
        # Reset state if requested
        if reset and os.path.exists(state_file):
            os.remove(state_file)
            print("Stack state reset for run-once mode")
        
        # Load state
        position_stack, last_processed_row, processed_transactions = load_stack_state(state_file)
        print(f"üìÇ Loaded state: stack={len(position_stack)}, last_row={last_processed_row}")
        
        # Check if input file exists
        if not os.path.exists(csv_file):
            print(f"‚è≥ Input file {csv_file} not found, skipping...")
            return True  # Not an error, just no data yet
        
        # Load and process data
        df = pd.read_csv(csv_file)
        if len(df) <= last_processed_row:
            print(f"‚úÖ No new rows to process (have {last_processed_row}, total {len(df)})")
            return True
        
        print(f"üîÑ Processing {len(df) - last_processed_row} new rows...")
        
        # Ensure output CSV has header
        if not os.path.exists(output_path):
            with open(output_path, "w", newline="") as f:
                csv.writer(f).writerow([
                    "Timestamp", "TradeQty", "TradePx", "RealisedPnL", "StackSize", "OrderId", "TimeStamp"
                ])
        
        # Process new rows only
        sell_events_processed = 0
        for i in range(last_processed_row, len(df)):
            row = df.iloc[i]
            
            # Create unique transaction ID for deduplication
            txn_id = (row.get('TimeStamp', ''), row.get('OrderId', ''), row.get('Quantity', 0), row.get('Price', 0))
            if txn_id in processed_transactions:
                continue
            processed_transactions.add(txn_id)
            
            # Process trade
            side = int(row.get('Side', 0))
            qty = float(row.get('Quantity', 0))
            price = float(row.get('Price', 0))
            
            if side == 1:  # BUY
                trade_qty = qty
            elif side == 2:  # SELL
                trade_qty = -qty
                sell_events_processed += 1
            else:
                continue
            
            # Execute LIFO logic
            try:
                pnl = calculate_lifo_pnl_and_update_stack(position_stack, trade_qty, price)
                
                # Write result
                if pnl != 0:
                    ts = f"{row.get('Date', '')} {row.get('Time', '')}"
                    with open(output_path, "a", newline="") as f:
                        csv.writer(f).writerow([ts, trade_qty, price, pnl, len(position_stack), row.get('OrderId', ''), row.get('TimeStamp', '')])
                    
            except ValueError as e:
                print(f"ERROR processing trade: {e}")
                # Write error to CSV for tracking
                ts = f"{row.get('Date', '')} {row.get('Time', '')}"
                with open(output_path, "a", newline="") as f:
                    csv.writer(f).writerow([ts, trade_qty, price, f"ERROR: {e}", len(position_stack), row.get('OrderId', ''), row.get('TimeStamp', '')])

        # Update last processed row and save state
        last_processed_row = len(df)
        save_stack_state(position_stack, last_processed_row, processed_transactions, state_file)
        print(f"‚úÖ Processed trades. Stack size: {len(position_stack)}")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Error in LIFO run-once: {e}")
        return False

# ---------------------------------------------------------------------------
# Main loop
# ---------------------------------------------------------------------------

def monitor(csv_path: str, output_path: str, poll: int = 5) -> None:
    # Load existing stack state or start fresh
    state_file = output_path.replace('.csv', '_state.pkl') # Creating a state file for the stack.
    position_stack, last_processed_row, processed_transactions = load_stack_state(state_file) # Loading the stack from the state file.
    
    print(f"Loaded state: stack_size={len(position_stack)}, last_row={last_processed_row}, processed_txns={len(processed_transactions)}")
    
    # Ensure output CSV has header
    if not os.path.exists(output_path): # If the output file does not exist, create it.
        with open(output_path, "w", newline="") as f:
            csv.writer(f).writerow([
                "Timestamp", "TradeQty", "TradePx", "RealisedPnL", "StackSize", "OrderId", "TimeStamp"
            ])

    print(f"Monitoring {csv_path} (poll every {poll}s)‚Ä¶")

    sell_events = 0
    save_counter = 0  # Save state every N iterations
    while True:
        if not os.path.exists(csv_path): 
            print(f"Waiting for {csv_path} ‚Ä¶")
            time.sleep(poll)
            continue

        try:
            df = pd.read_csv(csv_path)
        except Exception as exc:
            print(f"Error reading CSV: {exc}")
            time.sleep(poll)
            continue

        # Only process new rows
        if last_processed_row < len(df):
            new_rows = df.iloc[last_processed_row:]
            
            for idx, row in new_rows.iterrows():
                ts = parse_fill_datetime(row["Date"], row["Time"]) # Timestamp of the trade

                # Filter for specific criteria based on config
                if (row.get("Exchange", "") != config['exchange'] or 
                    row.get("Contract", "") != config['contract']):
                    continue
                
                side = int(row["Side"])     # 1 for buy, 2 for sell
                qty = float(row["Quantity"]) # Quantity of the trade
                px = float(row["Price"])     # Price of the trade
                
                # Create unique transaction ID using OrderId and TimeStamp from CSV
                transaction_id = f"{row.get('OrderId', '')}_{row.get('TimeStamp', '')}"
                
                if transaction_id in processed_transactions:
                    continue  # Skip duplicate
                
                processed_transactions.add(transaction_id)

                # Convert side to quantity (positive for buy, negative for sell)
                trade_qty = qty if side == 1 else -qty
                
                try:
                    # Calculate PnL and update stack in one call
                    pnl = calculate_lifo_pnl_and_update_stack(position_stack, trade_qty, px) # Calculating the PnL and updating the stack.
                    
                    # Write to output CSV for all trades (only non-zero PnL trades have realized gains/losses)
                    if pnl != 0:  # Only log trades that realize PnL
                        with open(output_path, "a", newline="") as f:
                            csv.writer(f).writerow([ts, trade_qty, px, pnl, len(position_stack), row.get('OrderId', ''), row.get('TimeStamp', '')])
                        print(f"TRADE: {ts} {trade_qty}@{px:.6f} PnL={pnl:.2f} stack={len(position_stack)} OrderId={row.get('OrderId', '')}")
                        
                    else:
                        print(f"TRADE: {ts} {trade_qty}@{px:.6f} (new position) stack={len(position_stack)} OrderId={row.get('OrderId', '')}")
                        
                except ValueError as e:
                    print(f"{ts} ERROR: {e}")
                    # Still write error to CSV for tracking
                    with open(output_path, "a", newline="") as f:
                        csv.writer(f).writerow([ts, trade_qty, px, f"ERROR: {e}", len(position_stack), row.get('OrderId', ''), row.get('TimeStamp', '')])
            
            last_processed_row = len(df)

        time.sleep(poll)

        # Save state periodically
        save_counter += 1
        if save_counter >= 10:  # Save state every 50 seconds
            save_stack_state(position_stack, last_processed_row, processed_transactions, state_file)
            save_counter = 0

# ---------------------------------------------------------------------------
if __name__ == "__main__":
    ap = argparse.ArgumentParser(description="Continuous LIFO PnL monitor")
    ap.add_argument("--csv-file", "-f", default=CONTINUOUS_FILLS_CSV)
    ap.add_argument("--output", "-o", default=LIFO_STREAMING_CSV)
    ap.add_argument("--interval", "-i", type=int, default=5, help="Polling interval seconds")
    ap.add_argument("--reset", action="store_true", help="Reset stack state and start fresh")
    ap.add_argument("--run-once", action="store_true", help="Run once and exit (for event-driven mode)")
    args = ap.parse_args()

    # Reset state if requested
    if args.reset:
        state_file = args.output.replace('.csv', '_state.pkl')
        if os.path.exists(state_file):
            os.remove(state_file)
            print("Stack state reset. Starting fresh.")

    if args.run_once:
        # Run once mode for event-driven processing
        success = process_lifo_once(args.csv_file, args.output, args.reset)
        print(f"üèÅ LIFO run-once completed: {'success' if success else 'errors'}")
        sys.exit(0 if success else 1)
    else:
        # Original continuous monitoring mode
        monitor(args.csv_file, args.output, args.interval) 